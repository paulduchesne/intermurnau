{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write to wikibase\n",
    "\n",
    "# a. install wikibase docker image (https://github.com/wmde/wikibase-docker) on digitalocean droplet.\n",
    "# b. or wipe previous install: docker-compose down --volumes\n",
    "# c. bring online: docker-compose up -d\n",
    "# d. run account create function.\n",
    "# e. updated localsettings: docker cp LocalSettings.php wikibase-docker_wikibase_1:/var/www/html/.\n",
    "# f. copy icon: docker cp icon-small.jpg wikibase-docker_wikibase_1:/var/www/html/images/.\n",
    "# g. restart base: docker-compose -f docker-compose.yml restart wikibase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "\n",
    "from wikibaseintegrator import wbi_core, wbi_login\n",
    "from IPython.display import clear_output\n",
    "import pathlib, requests, datetime, rdflib\n",
    "import pydash, time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate writing account\n",
    "\n",
    "def generate_account(password, user, address):\n",
    "    \n",
    "    # shamelessly adapted from here https://www.mediawiki.org/wiki/API:Account_creation\n",
    "\n",
    "    S = requests.Session()\n",
    "    wikiurl = f\"http://{address}:8181\"\n",
    "    endpoint = wikiurl + \"/w/api.php\"\n",
    "    PARAMS_0 = {'action':\"query\",'meta':\"tokens\",'type':\"createaccount\",'format':\"json\"}\n",
    "    R = S.get(url=endpoint, params=PARAMS_0)\n",
    "    DATA = R.json()\n",
    "    TOKEN = DATA['query']['tokens']['createaccounttoken']\n",
    "    PARAMS_1 = {'action': \"createaccount\",'createtoken': TOKEN,'username': user,\n",
    "        'password': password,'retype': password,'createreturnurl': wikiurl,'format': \"json\"}\n",
    "    R = S.post(endpoint, data=PARAMS_1)\n",
    "    print(R.json(), datetime.datetime.now())\n",
    "\n",
    "with open(pathlib.Path.home() / 'wikibase_password.md') as motdepasse:\n",
    "    motdepasse = motdepasse.read().replace('\\n','')        \n",
    "\n",
    "username = 'paulduchesne'\n",
    "wikibase_url = '167.99.135.149'    \n",
    "generate_account(motdepasse, username, wikibase_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define graph and namespace\n",
    "\n",
    "graph = rdflib.Graph()\n",
    "name_wb = rdflib.Namespace('http://wikibas.se/ontology')\n",
    "name_fiaf = rdflib.Namespace('https://www.fiafnet.org/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write properties\n",
    "\n",
    "def write_property(label, datatype, api_url):\n",
    "    localEntityEngine = wbi_core.ItemEngine.wikibase_item_engine_factory(mediawiki_api_url=api_url)\n",
    "    item = localEntityEngine(data=[])\n",
    "    if len(label):\n",
    "        for n, k in enumerate(label):\n",
    "            item.set_label(label[n], lang=label[n].language)  # no, go looking for a label!!\n",
    "    item.write(login_instance, entity_type=\"property\", property_datatype=datatype)\n",
    "    return item.item_id\n",
    "\n",
    "login_instance = wbi_login.Login(user=username, pwd=motdepasse, mediawiki_api_url=f'http://{wikibase_url}:8181/w/api.php')\n",
    "\n",
    "data = pathlib.Path.cwd().resolve().parents[0] / '3-merge' / 'merge.ttl'\n",
    "graph.parse(str(data), format=\"ttl\")\n",
    "    \n",
    "properties = pydash.uniq([b for a,b,c in graph])\n",
    "\n",
    "for y in [name_wb['#reference'], name_wb['#claim'], name_wb['#qualifier'], rdflib.RDFS.label]:\n",
    "    properties = [x for x in properties if x != y]\n",
    "\n",
    "prop_order = [\n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/instance_of'),\n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/work_type'),\n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/title'),\n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/forename'), \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/surname'), \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/gender'),   \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/production_country'),              \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/event'),\n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/agent'),               \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/item_of'),\n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/held_at'),              \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/manifestation'),  \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/manifestation_of'),               \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/item'),     \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/work'),                   \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/access'),      \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/carrier'),               \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/specific_carrier'), \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/element'),               \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/base'),                              \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/colour'),              \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/sound'),  \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/sound_format'),      \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/maintitles_language'),  \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/intertitles_language'),               \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/extent_metres'),  \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/extent_feet'),                \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/duration'),    \n",
    "    rdflib.term.URIRef('https://www.fiafnet.org/ontology/property/external_id')]\n",
    "\n",
    "prop_order += [x for x in properties if x not in prop_order]\n",
    "\n",
    "api_url = f'http://{wikibase_url}:8181/w/api.php'\n",
    "property_dict = dict()    \n",
    "\n",
    "for p in prop_order:\n",
    "    labels = [o for s,v,o in graph.triples((p, rdflib.RDFS.label, None))]\n",
    "    for x in [o for s,v,o in graph.triples((None, p, None))][:1]:\n",
    "        if type(x) == type(rdflib.URIRef('')):\n",
    "            datatype = 'wikibase-item'\n",
    "        elif type(x) == type(rdflib.Literal('')):\n",
    "            datatype = 'string'            \n",
    "        else:\n",
    "            raise Exception('Unknown property datatype.')\n",
    "    property_dict[p] = write_property(labels, datatype, api_url)\n",
    "    \n",
    "rewrite = rdflib.Graph()\n",
    "for s,v,o in graph:\n",
    "    if v in property_dict.keys():\n",
    "        v = rdflib.URIRef(property_dict[v])\n",
    "    rewrite.add((s,v,o))  \n",
    "graph = rewrite\n",
    "\n",
    "print(datetime.datetime.now(), ';', len(graph), 'triples.')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write items\n",
    "\n",
    "claims = [o for s,p,o in graph.triples((None, name_wb['#claim'], None))] \n",
    "qualifiers = [o for s,p,o in graph.triples((None, name_wb['#qualifier'], None))] \n",
    "references = [o for s,p,o in graph.triples((None, name_wb['#reference'], None))] \n",
    "undesirable = claims+qualifiers+references\n",
    "\n",
    "cleaned = rdflib.Graph()\n",
    "for s,p,o in graph:\n",
    "    cleaned.add((s,p,o))\n",
    "cleaned.remove((None, rdflib.RDFS.label, None))\n",
    "\n",
    "items = pydash.uniq([s for s,p,o in cleaned if s not in undesirable])\n",
    "items += pydash.uniq([o for s,p,o in cleaned if o not in undesirable and isinstance(o, rdflib.URIRef)])\n",
    "items = pydash.uniq(items)\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "for num, i in enumerate(items):\n",
    "\n",
    "    num = num+1\n",
    "    duration = (datetime.datetime.now()-start)/num # this is how long per loop\n",
    "    eta = (duration * (len(items)-num))+datetime.datetime.now()\n",
    "    print('running:', num, 'of', len(items), ';', round((num/len(items))*100, 2), '% ; eta:', eta)\n",
    "    clear_output(wait=True)      \n",
    "    \n",
    "    wd_item = wbi_core.ItemEngine(data=[], mediawiki_api_url=f'http://{wikibase_url}:8181/w/api.php')\n",
    "    label = [o for s,v,o in graph.triples((i, rdflib.RDFS.label, None))]\n",
    "    if len(label):\n",
    "        for n, k in enumerate(label):\n",
    "            wd_item.set_label(label[n], lang=label[n].language)  \n",
    "    wd_item.write(login_instance)    \n",
    "    \n",
    "    rewrite = rdflib.Graph()\n",
    "    for s,v,o in graph:\n",
    "        if s == i:\n",
    "            s = rdflib.URIRef(wd_item.item_id)\n",
    "        if o == i:\n",
    "            o = rdflib.URIRef(wd_item.item_id)\n",
    "        rewrite.add((s,v,o))\n",
    "    graph = rewrite\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "print(datetime.datetime.now(), ';', len(graph), 'triples.')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write claims\n",
    "\n",
    "elements = pydash.uniq([a for a,b,c in graph.triples((None, name_wb['#claim'], None))])\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "for num, elem in enumerate(elements):\n",
    "\n",
    "    num = num+1\n",
    "    duration = (datetime.datetime.now()-start)/num # this is how long per loop\n",
    "    eta = (duration * (len(elements)-num))+datetime.datetime.now()\n",
    "    print('running:', num, 'of', len(elements), ';', round((num/len(elements))*100, 2), '% ; eta:', eta)\n",
    "    clear_output(wait=True)    \n",
    " \n",
    "    collected = [(a,b,c) for a,b,c in graph.triples((elem, name_wb['#claim'], None))]\n",
    "    new_list = list()\n",
    "    for a,b,c in collected:\n",
    "        for d,e,f in graph.triples((c, None, None)):\n",
    "            if e != name_wb['#reference'] and e != name_wb['#qualifier']:\n",
    "                prop_order = str(e.replace('P','')).zfill(4)\n",
    "                new_list.append((c,e, prop_order))\n",
    "\n",
    "    new_list = sorted(new_list, key=lambda x:x[2]) \n",
    "    for y in sorted(pydash.uniq([x[2] for x in new_list])):\n",
    "        sub_list = [x for x in new_list if x[2] == y]\n",
    "\n",
    "        claimer = list()    \n",
    "        for c, n, xx in sub_list:\n",
    "\n",
    "            quals = list()\n",
    "            for d,e,f in graph.triples((c, None, None)):\n",
    "                if e == name_wb['#qualifier']:\n",
    "                    quals.append(f)\n",
    "\n",
    "            qual2 = list()\n",
    "            for q in quals:\n",
    "                for g,h,i in graph.triples((q, None, None)):\n",
    "                    if isinstance(i, rdflib.URIRef):                    \n",
    "                        qual2.append(wbi_core.ItemID(value=i, prop_nr=h, is_qualifier=True))\n",
    "                    elif isinstance(i, rdflib.Literal):            \n",
    "                        qual2.append(wbi_core.String(value=i, prop_nr=h, is_qualifier=True)) \n",
    "                    else:\n",
    "                        raise Exception('no proper datatype!')                          \n",
    "\n",
    "            refs = list()\n",
    "            for d,e,f in graph.triples((c, None, None)):\n",
    "                if e == name_wb['#reference']:\n",
    "                    refs.append(f)\n",
    "\n",
    "            refs2 = list()\n",
    "            for r in refs:\n",
    "                for g,h,i in graph.triples((r, None, None)):\n",
    "                    refs2.append([wbi_core.ItemID(value=i, prop_nr=h, is_reference=True)])\n",
    "\n",
    "            for d,e,f in graph.triples((c, None, None)):\n",
    "                if e != name_wb['#reference'] and e != name_wb['#qualifier']:\n",
    "                    if isinstance(f, rdflib.URIRef):\n",
    "                        claimer.append(wbi_core.ItemID(value=str(f), prop_nr=str(e), qualifiers=qual2, references=pydash.uniq(refs2)))\n",
    "                    elif isinstance(f, rdflib.Literal):\n",
    "                        claimer.append(wbi_core.String(value=str(f), prop_nr=str(e), qualifiers=qual2, references=pydash.uniq(refs2)))\n",
    "                    else:\n",
    "                        raise Exception('no proper datatype!')  \n",
    "\n",
    "        wd_item = wbi_core.ItemEngine(item_id=str(elem), data=claimer, \n",
    "                                      mediawiki_api_url=f'http://{wikibase_url}:8181/w/api.php')\n",
    "        wd_item.write(login_instance)  \n",
    "        \n",
    "    time.sleep(1)        \n",
    "\n",
    "print(datetime.datetime.now(), ';', len(graph), 'triples.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
