{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Swedish Film Institute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "\n",
    "import rdflib, pandas, pathlib, json\n",
    "import numpy, uuid, xmltodict, pydash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define graph and namespace\n",
    "\n",
    "graph = rdflib.Graph()\n",
    "name_sfi = rdflib.Namespace('https://www.filminstitutet.se/') \n",
    "name_wb = rdflib.Namespace('http://wikibas.se/ontology')\n",
    "name_fiaf = rdflib.Namespace('https://www.fiafnet.org/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# useful functions\n",
    "\n",
    "def make_claim(s, p, o):        \n",
    "    claim_id = name_sfi[f\"resource/claim/{uuid.uuid4()}\"]    \n",
    "    graph.add((s, name_wb['#claim'], claim_id))\n",
    "    graph.add((claim_id, p, o))\n",
    "    return claim_id\n",
    "\n",
    "def make_qual(s, p, o):\n",
    "    qual_id = name_sfi[f\"resource/qualifier/{uuid.uuid4()}\"]       \n",
    "    graph.add((s, name_wb['#qualifier'], qual_id))\n",
    "    graph.add((qual_id, p, o))\n",
    "    return qual_id\n",
    "\n",
    "def reference(claim_id, institute):\n",
    "    ref_id = name_sfi[f\"resource/reference/{uuid.uuid4()}\"]\n",
    "    graph.add((claim_id, name_wb['#reference'], ref_id))\n",
    "    graph.add((ref_id, name_fiaf['ontology/property/contributed_by'], institute))  \n",
    "    \n",
    "def single_list(data):  \n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "    else:\n",
    "        return [data]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define institution\n",
    "\n",
    "graph.add((name_sfi['ontology/item/sfi'], rdflib.RDFS.label, rdflib.Literal('Swedish Film Institute', lang='en'))) \n",
    "graph.add((name_sfi['ontology/item/sfi'], rdflib.RDFS.label, rdflib.Literal('Svenska Filminstitutet', lang='sv'))) \n",
    "make_claim(name_sfi['ontology/item/sfi'], name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/holding_institution'])\n",
    "make_claim(name_sfi['ontology/item/sfi'], name_fiaf['ontology/property/located_in'], name_fiaf['ontology/item/sweden'])\n",
    "\n",
    "print(len(graph)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# format data\n",
    "\n",
    "datapath = pathlib.Path.cwd() / 'Murnau.xml'\n",
    "with open(datapath) as data:\n",
    "    data = xmltodict.parse(data.read())    \n",
    "    data = json.loads(json.dumps(data))\n",
    "    \n",
    "with open(pathlib.Path.cwd() / 'sfi.json', 'w') as sfi_test:\n",
    "    json.dump(data, sfi_test)\n",
    "\n",
    "data = [x for x in pydash.get(data, 'adlibXML.recordList.record')] \n",
    "\n",
    "print(len(graph)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write work\n",
    "\n",
    "for x in data:\n",
    "    work_id = x['object_number']\n",
    "    work = name_sfi[f\"resource/work/{work_id}\"]\n",
    "    \n",
    "    make_claim(work, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/work'])\n",
    "    claim1 = make_claim(work, name_fiaf['ontology/property/external_id'], rdflib.Literal(work_id))\n",
    "    make_qual(claim1, name_fiaf['ontology/property/institution'], name_sfi['ontology/item/sfi'])\n",
    "    reference(claim1, name_sfi['ontology/item/sfi'])     \n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write title\n",
    "\n",
    "for x in data:\n",
    "    \n",
    "    work_id = x['object_number']\n",
    "    work = name_sfi[f\"resource/work/{work_id}\"]\n",
    "\n",
    "    for t in single_list(x['Title']):\n",
    "        if 'Originaltitel' in str(t): \n",
    "            claim1 = make_claim(work, name_fiaf['ontology/property/title'], rdflib.Literal(t['title_complete']))\n",
    "            make_qual(claim1, name_fiaf['ontology/property/title_type'], name_fiaf['ontology/item/original_title'])\n",
    "            reference(claim1, name_sfi['ontology/item/sfi'])      \n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write country\n",
    "\n",
    "for x in data:\n",
    "    \n",
    "    work_id = x['object_number']\n",
    "    work = name_sfi[f\"resource/work/{work_id}\"]\n",
    "\n",
    "    for k, v in {'Germany':name_fiaf['ontology/item/germany'], 'USA':name_fiaf['ontology/item/usa']}.items():\n",
    "        if pydash.get(x, 'production_country.value.0.#text') == k:\n",
    "            claim_id = make_claim(work, name_fiaf['ontology/property/production_country'], v)  \n",
    "            reference(claim_id, name_sfi['ontology/item/sfi'])     \n",
    "            \n",
    "print(len(graph)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8696\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write agents\n",
    "\n",
    "def write_credit(top_branch, lower_branch, credit_level, agent_type, datum):\n",
    "    work = name_sfi[f\"resource/work/{x['object_number']}\"]  \n",
    "    \n",
    "    if top_branch in datum:\n",
    "        for a in single_list(pydash.get(datum, top_branch)):\n",
    "            if lower_branch != 'cast':\n",
    "                credit_type = a['credit.type']    \n",
    "            else:\n",
    "                credit_type = a['cast.credit_type']\n",
    "                \n",
    "            if credit_level == pydash.get(credit_type, 'value.0.#text'):\n",
    "\n",
    "                if pydash.get(a, f'{lower_branch}\\.name.pseudonym_for'):\n",
    "                    agent_id = pydash.get(a, f'{lower_branch}\\.name.pseudonym_for.id_number')\n",
    "                    fore = pydash.get(a, f'{lower_branch}\\.name.pseudonym_for.forename')                    \n",
    "                    sur = pydash.get(a, f'{lower_branch}\\.name.pseudonym_for.surname')    \n",
    "                    \n",
    "                else:\n",
    "                    agent_id = pydash.get(a, f'{lower_branch}\\.name.id_number')\n",
    "                    fore = pydash.get(a, f'{lower_branch}\\.name.forename')                    \n",
    "                    sur = pydash.get(a, f'{lower_branch}\\.name.surname')    \n",
    "                \n",
    "                if agent_id != '254560':\n",
    "                    agent = name_sfi[f\"resource/agent/{agent_id}\"]            \n",
    "\n",
    "                    claim1 = make_claim(work, name_fiaf['ontology/property/agent'], agent)\n",
    "                    make_qual(claim1, name_fiaf['ontology/property/agent_type'], agent_type)                \n",
    "                    reference(claim1, name_sfi['ontology/item/sfi'])   \n",
    "\n",
    "                    make_claim(agent, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/agent']) \n",
    "\n",
    "                    claim2 = make_claim(agent, name_fiaf['ontology/property/external_id'], rdflib.Literal(agent_id))\n",
    "                    make_qual(claim2, name_fiaf['ontology/property/institution'], name_sfi['ontology/item/sfi'])\n",
    "                    reference(claim2, name_sfi['ontology/item/sfi']) \n",
    "\n",
    "                    if fore != None:\n",
    "                        claim3 = make_claim(agent, name_fiaf['ontology/property/forename'], rdflib.Literal(fore))\n",
    "                        reference(claim3, name_sfi['ontology/item/sfi'])                \n",
    "\n",
    "                    claim4 = make_claim(agent, name_fiaf['ontology/property/surname'], rdflib.Literal(sur))\n",
    "                    reference(claim4, name_sfi['ontology/item/sfi'])        \n",
    "\n",
    "                    claim9 = make_claim(agent, name_fiaf['ontology/property/work'], work)    \n",
    "                    reference(claim9, name_sfi['ontology/item/sfi'])              \n",
    "\n",
    "for x in data:\n",
    "    write_credit('Cast', 'cast', 'Cast', name_fiaf['ontology/item/cast'], x)\n",
    "    write_credit('Credits', 'credit', 'Director', name_fiaf['ontology/item/director'], x) \n",
    "    write_credit('Credits', 'credit', 'Screenplay', name_fiaf['ontology/item/screenwriter'], x) \n",
    "    write_credit('Credits', 'credit', 'Producer', name_fiaf['ontology/item/producer'], x) \n",
    "    write_credit('Credits', 'credit', 'Director of Photography', name_fiaf['ontology/item/cinematographer'], x) \n",
    "    write_credit('Credits', 'credit', 'Music', name_fiaf['ontology/item/composer'], x)  \n",
    "    write_credit('Credits', 'credit', 'Film Editor', name_fiaf['ontology/item/editor'], x)      \n",
    "    \n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write events\n",
    "\n",
    "for x in data:\n",
    "    work = name_sfi[f\"resource/work/{x['object_number']}\"]      \n",
    "    if 'Publication_event' in x:\n",
    "        collected_events = list()\n",
    "        for y in single_list(pydash.get(x, 'Publication_event')):\n",
    "            event_type = y['event.publication.number']['event.sub_type']\n",
    "            if pydash.get(event_type, 'value.0.#text') == 'Release in Sweden':\n",
    "                collected_events.append(('swedish release', y['event.publication.number']['date_start']))\n",
    "  \n",
    "        collected_events = pydash.uniq([x for x in collected_events])\n",
    "        \n",
    "        for a,b in collected_events:\n",
    "            claim1 = make_claim(work, name_fiaf['ontology/property/event'], rdflib.Literal(b))\n",
    "            make_qual(claim1, name_fiaf['ontology/property/event_type'], name_fiaf['ontology/item/publication']) \n",
    "            make_qual(claim1, name_fiaf['ontology/property/country'], name_fiaf['ontology/item/sweden'])   \n",
    "            reference(claim1, name_sfi['ontology/item/sfi'])             \n",
    "\n",
    "for x in data:\n",
    "    work = name_sfi[f\"resource/work/{x['object_number']}\"]      \n",
    "    if 'Decision_event' in x:\n",
    "        for c in single_list(pydash.get(x, 'Decision_event')):\n",
    "            date = pydash.get(c, 'event\\.decision\\.number.date_start')\n",
    "            cert = pydash.get(c, 'event\\.decision\\.number.decision\\.audience_rating.value.0.#text')\n",
    "            \n",
    "            claim1 = make_claim(work, name_fiaf['ontology/property/event'], rdflib.Literal(date))\n",
    "            make_qual(claim1, name_fiaf['ontology/property/event_type'], name_fiaf['ontology/item/decision_censorship']) \n",
    "            make_qual(claim1, name_fiaf['ontology/property/country'], name_fiaf['ontology/item/sweden'])  \n",
    "            make_qual(claim1, name_fiaf['ontology/property/certificate'], rdflib.Literal(cert))              \n",
    "            reference(claim1, name_sfi['ontology/item/sfi'])         \n",
    "            \n",
    "print(len(graph))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9316\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write manifestations/items\n",
    "\n",
    "for x in data:\n",
    "    work = name_sfi[f\"resource/work/{x['object_number']}\"]  \n",
    "    parts = single_list(pydash.get(x, 'Parts.parts\\.reference.Parts'))\n",
    "    \n",
    "    for p in [x for x in parts if x != None]:\n",
    "        \n",
    "        manifestation = name_sfi[f\"resource/manifestation/{uuid.uuid4()}\"]\n",
    "        make_claim(manifestation, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/manifestation'])\n",
    "        make_claim(manifestation, name_fiaf['ontology/property/manifestation_of'], work)\n",
    "\n",
    "        item_id = pydash.get(p, 'parts\\.reference.object_number')\n",
    "        item = name_sfi[f\"resource/item/{item_id}\"]     \n",
    "\n",
    "        make_claim(item, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/item'])        \n",
    "        make_claim(item, name_fiaf['ontology/property/item_of'], manifestation)  \n",
    "\n",
    "        claim1 = make_claim(item, name_fiaf['ontology/property/held_at'], name_sfi['ontology/item/sfi'])\n",
    "        reference(claim1, name_sfi['ontology/item/sfi'])          \n",
    "        \n",
    "        claim2 = make_claim(item, name_fiaf['ontology/property/external_id'], rdflib.Literal(item_id))\n",
    "        make_qual(claim2, name_fiaf['ontology/property/institution'], name_sfi['ontology/item/sfi'])\n",
    "        reference(claim2, name_sfi['ontology/item/sfi'])         \n",
    "\n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/carrier'], name_fiaf['ontology/item/film'])   \n",
    "        reference(claim_id, name_sfi['ontology/item/sfi'])             \n",
    "        \n",
    "        for k, v in {'16 mm':name_fiaf['ontology/item/16mm'], '35 mm':name_fiaf['ontology/item/35mm']}.items():\n",
    "            if pydash.get(p, 'parts\\.reference.carrier_type_specific.value.0.#text') == k:                       \n",
    "                claim3 = make_claim(item, name_fiaf['ontology/property/specific_carrier'], v)   \n",
    "                reference(claim3, name_sfi['ontology/item/sfi'])                 \n",
    "\n",
    "        for k, v in {'Acetate':name_fiaf['ontology/item/acetate']}.items():\n",
    "            if pydash.get(p, 'parts\\.reference.Material.material.value.0.#text') == k:\n",
    "                claim4 = make_claim(item, name_fiaf['ontology/property/base'], v)   \n",
    "                reference(claim4, name_sfi['ontology/item/sfi'])                \n",
    "\n",
    "        for k, v in {'Print':name_fiaf['ontology/item/print'], 'Duplicate negative':name_fiaf['ontology/item/duplicate_negative']}.items():\n",
    "            if pydash.get(p, 'parts\\.reference.Object_name.object_name.value.0.#text') == k:\n",
    "                claim5 = make_claim(item, name_fiaf['ontology/property/element'], v)   \n",
    "                reference(claim5, name_sfi['ontology/item/sfi'])                \n",
    "                \n",
    "        ext = pydash.get(p, 'parts\\.reference.Dimension.dimension\\.value')\n",
    "        if ext:\n",
    "            claim6 = make_claim(item, name_fiaf['ontology/property/extent_metres'], rdflib.Literal(ext))\n",
    "            reference(claim6, name_sfi['ontology/item/sfi'])             \n",
    "\n",
    "        make_claim(work, name_fiaf['ontology/property/manifestation'], manifestation)\n",
    "        make_claim(manifestation, name_fiaf['ontology/property/item'], item)                    \n",
    "\n",
    "print(len(graph)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9316\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph.serialize(destination=str(pathlib.Path.cwd() / 'sfi.ttl'), format=\"turtle\")\n",
    "print(len(graph))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
