{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# british film institute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "\n",
    "import rdflib, pandas, pathlib, json\n",
    "import numpy, uuid, xmltodict, pydash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define graph and namespace\n",
    "\n",
    "graph = rdflib.Graph()\n",
    "name_bfi = rdflib.Namespace('https://www.bfi.org.uk/') \n",
    "name_wb = rdflib.Namespace('http://wikibas.se/ontology')\n",
    "name_fiaf = rdflib.Namespace('https://www.fiafnet.org/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# useful functions\n",
    "\n",
    "def make_claim(s, p, o):        \n",
    "    claim_id = name_bfi[f\"resource/claim/{uuid.uuid4()}\"]    \n",
    "    graph.add((s, name_wb['#claim'], claim_id))\n",
    "    graph.add((claim_id, p, o))\n",
    "    return claim_id\n",
    "\n",
    "def make_qual(s, p, o):\n",
    "    qual_id = name_bfi[f\"resource/qualifier/{uuid.uuid4()}\"]       \n",
    "    graph.add((s, name_wb['#qualifier'], qual_id))\n",
    "    graph.add((qual_id, p, o))\n",
    "    return qual_id\n",
    "\n",
    "def reference(claim_id, institute):\n",
    "    ref_id = name_bfi[f\"resource/reference/{uuid.uuid4()}\"]\n",
    "    graph.add((claim_id, name_wb['#reference'], ref_id))\n",
    "    graph.add((ref_id, name_fiaf['ontology/property/contributed_by'], institute))  \n",
    "    \n",
    "def single_list(data):  \n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "    else:\n",
    "        return [data]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define institution\n",
    "\n",
    "graph.add((name_bfi['ontology/item/bfi'], rdflib.RDFS.label, rdflib.Literal('British Film Institute', lang='en'))) \n",
    "make_claim(name_bfi['ontology/item/bfi'], name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/holding_institution'])\n",
    "make_claim(name_bfi['ontology/item/bfi'], name_fiaf['ontology/property/located_in'], name_fiaf['ontology/item/uk'])\n",
    "\n",
    "print(len(graph)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# format data\n",
    "\n",
    "path = pathlib.Path.home() / 'murnau-data' / 'british_film_institute'\n",
    "\n",
    "with open(path / 'BFI_Murnau_Works.json') as data:    \n",
    "    data = [x for x in pydash.get(json.load(data), 'adlibJSON.recordList.record')] \n",
    "\n",
    "print(len(graph)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write work\n",
    "\n",
    "graph.add((name_bfi['ontology/item/wikidata'], rdflib.RDFS.label, rdflib.Literal('Wikidata', lang='en'))) \n",
    "\n",
    "for x in data:\n",
    "    work_id = x['object_number'][0]\n",
    "    work = name_bfi[f\"resource/work/{work_id}\"]\n",
    "    \n",
    "    make_claim(work, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/work'])\n",
    "    claim1 = make_claim(work, name_fiaf['ontology/property/external_id'], rdflib.Literal(work_id))\n",
    "    make_qual(claim1, name_fiaf['ontology/property/institution'], name_bfi['ontology/item/bfi'])\n",
    "    reference(claim1, name_bfi['ontology/item/bfi']) \n",
    "\n",
    "    for y in pydash.get(x, 'URL'):\n",
    "        if 'Wikidata' in pydash.get(y, 'URL\\.description.0'):            \n",
    "            wikidata_id = pydash.get(y, 'URL.0').split('/')[-1]\n",
    "            claim_id = make_claim(work, name_fiaf['ontology/property/external_id'], rdflib.Literal(wikidata_id))\n",
    "            make_qual(claim_id, name_fiaf['ontology/property/institution'], name_bfi['ontology/item/wikidata'])\n",
    "            reference(claim_id, name_bfi['ontology/item/bfi'])             \n",
    "\n",
    "    if pydash.get(x, 'worklevel_type.0.value.1') == 'Monographic':\n",
    "        claim_id = make_claim(work, name_fiaf['ontology/property/work_type'], name_fiaf['ontology/item/monographic'])\n",
    "        reference(claim_id, name_bfi['ontology/item/bfi'])\n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write title\n",
    "\n",
    "for x in data:\n",
    "    \n",
    "    work_id = x['object_number'][0]\n",
    "    work = name_bfi[f\"resource/work/{work_id}\"]\n",
    "    \n",
    "    orig = [y for y in pydash.get(x, 'Title') if 'Original' in str(y)][0]\n",
    "    title = pydash.get(orig, 'title')[0]\n",
    "    if pydash.get(orig, 'title\\.article') is not None:\n",
    "        title = pydash.get(orig, 'title\\.article')[0]+' '+title\n",
    "        \n",
    "    claim1 = make_claim(work, name_fiaf['ontology/property/title'], rdflib.Literal(title.strip()))\n",
    "    make_qual(claim1, name_fiaf['ontology/property/title_type'], name_fiaf['ontology/item/original_title'])\n",
    "    reference(claim1, name_bfi['ontology/item/bfi'])      \n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write country\n",
    "\n",
    "for x in data:\n",
    "    \n",
    "    work_id = x['object_number'][0]\n",
    "    work = name_bfi[f\"resource/work/{work_id}\"]\n",
    "    \n",
    "    for k, v in {'Germany':name_fiaf['ontology/item/germany'], 'USA':name_fiaf['ontology/item/usa']}.items():\n",
    "        if pydash.get(x, 'production_country.0.term.0') == k:\n",
    "            claim_id = make_claim(work, name_fiaf['ontology/property/production_country'], v)  \n",
    "            reference(claim_id, name_bfi['ontology/item/bfi'])         \n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10408\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write agent\n",
    "\n",
    "def write_credit(source, contribution, uri):\n",
    "\n",
    "    for s in [x for x in source if x['role'] == contribution]:\n",
    "        \n",
    "        work = s['work']\n",
    "        agent = name_bfi[f\"resource/agent/{s['id']}\"]            \n",
    "\n",
    "        claim_id = make_claim(work, name_fiaf['ontology/property/agent'], agent)\n",
    "        make_qual(claim_id, name_fiaf['ontology/property/agent_type'], uri)                \n",
    "        reference(claim_id, name_bfi['ontology/item/bfi'])   \n",
    "\n",
    "        make_claim(agent, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/agent']) \n",
    "\n",
    "        claim_id = make_claim(agent, name_fiaf['ontology/property/external_id'], rdflib.Literal(s['id']))\n",
    "        make_qual(claim_id, name_fiaf['ontology/property/institution'], name_bfi['ontology/item/bfi'])\n",
    "        reference(claim_id, name_bfi['ontology/item/bfi']) \n",
    "        \n",
    "        claim_id = make_claim(agent, name_fiaf['ontology/property/surname'], rdflib.Literal(s['name'][0].strip()))\n",
    "        reference(claim_id, name_bfi['ontology/item/bfi']) \n",
    "        \n",
    "        if len(s['name']) > 1:\n",
    "            claim_id = make_claim(agent, name_fiaf['ontology/property/forename'], rdflib.Literal(s['name'][1].strip()))\n",
    "            reference(claim_id, name_bfi['ontology/item/bfi'])             \n",
    "\n",
    "        claim_id = make_claim(agent, name_fiaf['ontology/property/work'], work)    \n",
    "        reference(claim_id, name_bfi['ontology/item/bfi'])               \n",
    "\n",
    "combined = list()\n",
    "for x in data:\n",
    "    work_id = x['object_number'][0]\n",
    "    work = name_bfi[f\"resource/work/{work_id}\"]\n",
    "\n",
    "    for y in pydash.get(x, 'cast'):\n",
    "        name = pydash.get(y, 'cast\\.name.0.name')[0].split(',')\n",
    "        credit_type = pydash.get(y, 'cast\\.name.0.party\\.class.0.value')[0]\n",
    "        agent_id = pydash.get(y, 'cast\\.name\\.lref')[0]\n",
    "        combined.append({'work': work, 'id':agent_id, 'name':name, 'type':credit_type, 'role':'Cast'})\n",
    "        \n",
    "    for y in pydash.get(x, 'credits'):\n",
    "        name = pydash.get(y, 'credit\\.name.0.name')[0].split(',')\n",
    "        credit_type = pydash.get(y, 'credit\\.name.0.party\\.class.0.value')[0]        \n",
    "        role = pydash.get(y, 'credit\\.type.0.term')[0]\n",
    "        agent_id = pydash.get(y, 'credit\\.name\\.lref')[0]\n",
    "        combined.append({'work': work, 'id':agent_id, 'name':name, 'type':credit_type, 'role':role})    \n",
    "        \n",
    "combined = [x for x in combined if x['type'] == 'PERSON']  \n",
    "\n",
    "write_credit(combined, 'Cast', name_fiaf['ontology/item/cast'])                    \n",
    "write_credit(combined, 'Director', name_fiaf['ontology/item/director']) \n",
    "write_credit(combined, 'Screenplay', name_fiaf['ontology/item/screenwriter']) \n",
    "write_credit(combined, 'Producer', name_fiaf['ontology/item/producer']) \n",
    "write_credit(combined, 'Photography', name_fiaf['ontology/item/cinematographer']) \n",
    "write_credit(combined, 'Music', name_fiaf['ontology/item/composer'])  \n",
    "write_credit(combined, 'Editor', name_fiaf['ontology/item/editor'])      \n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12438\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write manifestations/items\n",
    "\n",
    "items = list()\n",
    "for x in data:\n",
    "    work_id = x['object_number'][0]\n",
    "    for manifestation in pydash.get(x, 'Parts'):\n",
    "        for item in pydash.get(manifestation, 'parts_reference'):\n",
    "            if 'Parts' in item:\n",
    "                for carrier in pydash.get(item, 'Parts'):\n",
    "                    \n",
    "                    carrier = pydash.get(carrier, 'parts_reference.0')\n",
    "                    \n",
    "                    item_id = pydash.get(carrier, 'object_number.0')  \n",
    "                    copy_status = pydash.get(carrier, 'copy_status.0.value.1')                    \n",
    "                    item_type = pydash.get(carrier, 'item_type.0.value.0') \n",
    "                    sound = pydash.get(carrier, 'sound_item.0.value.1') \n",
    "                    base = pydash.get(carrier, 'base.0.value.1')   \n",
    "                    phys = pydash.get(carrier, 'physical_description')   \n",
    "                    gauge = pydash.get(carrier, 'gauge_film.0.value.1')  \n",
    "                    vid_form = pydash.get(carrier, 'video_format.0.value.0') \n",
    "                    if 'Dimension' in carrier:\n",
    "                        duration = [y for y in pydash.get(carrier, 'Dimension') if pydash.get(y, 'dimension\\.part.0') == 'Total']\n",
    "                        duration = pydash.get(duration, '0.dimension\\.value.0')\n",
    "                    else:\n",
    "                        duration = None\n",
    "                    \n",
    "                    items.append({'work_id':work_id, 'item_id':item_id, 'copy':copy_status, 'item_type':item_type, \n",
    "                                  'sound':sound, 'base':base, 'element':phys, 'gauge':gauge, 'video':vid_form, 'dure':duration})\n",
    "\n",
    "for i in items:\n",
    "    if i['copy'] != 'Removed':\n",
    "\n",
    "        work = name_bfi[f\"resource/work/{i['work_id']}\"]\n",
    "\n",
    "        manifestation = name_bfi[f\"resource/manifestation/{uuid.uuid4()}\"]\n",
    "        make_claim(manifestation, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/manifestation'])\n",
    "        make_claim(manifestation, name_fiaf['ontology/property/manifestation_of'], work)\n",
    "\n",
    "        item_id = i['item_id']\n",
    "        item = name_bfi[f\"resource/item/{item_id}\"]     \n",
    "\n",
    "        make_claim(item, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/item'])        \n",
    "        make_claim(item, name_fiaf['ontology/property/item_of'], manifestation)  \n",
    "\n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/held_at'], name_bfi['ontology/item/bfi'])\n",
    "        reference(claim_id, name_bfi['ontology/item/bfi'])          \n",
    "\n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/external_id'], rdflib.Literal(item_id))\n",
    "        make_qual(claim_id, name_fiaf['ontology/property/institution'], name_bfi['ontology/item/bfi'])\n",
    "        reference(claim_id, name_bfi['ontology/item/bfi'])  \n",
    "\n",
    "        for k, v in {'FILM':name_fiaf['ontology/item/film'], \n",
    "                     'VIDEO':name_fiaf['ontology/item/video_tape'], 'DIGITAL':name_fiaf['ontology/item/digital']}.items():\n",
    "            if i['item_type'] == k:                       \n",
    "                claim_id = make_claim(item, name_fiaf['ontology/property/carrier'], v)   \n",
    "                reference(claim_id, name_bfi['ontology/item/bfi'])  \n",
    "                \n",
    "        for k, v in {'16mm':name_fiaf['ontology/item/16mm'], '35mm':name_fiaf['ontology/item/35mm']}.items():\n",
    "            if i['gauge'] == k:                       \n",
    "                claim_id = make_claim(item, name_fiaf['ontology/property/specific_carrier'], v)   \n",
    "                reference(claim_id, name_bfi['ontology/item/bfi'])  \n",
    "                \n",
    "        for k, v in {'Safety':name_fiaf['ontology/item/acetate'], 'Acetate':name_fiaf['ontology/item/acetate'],\n",
    "                     'Nitrate':name_fiaf['ontology/item/nitrate'], 'Polyester':name_fiaf['ontology/item/polyester']}.items():\n",
    "            if i['base'] == k:                       \n",
    "                claim_id = make_claim(item, name_fiaf['ontology/property/base'], v)   \n",
    "                reference(claim_id, name_bfi['ontology/item/bfi'])                  \n",
    "\n",
    "        for k, v in {'Silent':name_fiaf['ontology/item/silent'], 'Combined':name_fiaf['ontology/item/sound'],\n",
    "                     'Mute':name_fiaf['ontology/item/silent'], 'Mixed':name_fiaf['ontology/item/sound']}.items():\n",
    "            if i['sound'] == k:                       \n",
    "                claim_id = make_claim(item, name_fiaf['ontology/property/sound'], v)   \n",
    "                reference(claim_id, name_bfi['ontology/item/bfi'])                  \n",
    "\n",
    "        for k, v in {'Master':name_fiaf['ontology/item/master'], 'Viewing':name_fiaf['ontology/item/viewing']}.items():\n",
    "            if i['copy'] == k:                       \n",
    "                claim_id = make_claim(item, name_fiaf['ontology/property/access'], v)   \n",
    "                reference(claim_id, name_bfi['ontology/item/bfi'])         \n",
    "                \n",
    "        for k, v in {\n",
    "            'Dupe Negative':name_fiaf['ontology/item/duplicate_negative'], \n",
    "            'BW Positive':name_fiaf['ontology/item/print'], \n",
    "            'Negative':name_fiaf['ontology/item/negative'], \n",
    "            'Duplicating Positive':name_fiaf['ontology/item/duplicate_positive'], \n",
    "            'Colour Positive':name_fiaf['ontology/item/print']}.items():\n",
    "            if i['element'] == k:                       \n",
    "                claim_id = make_claim(item, name_fiaf['ontology/property/element'], v)   \n",
    "                reference(claim_id, name_bfi['ontology/item/bfi']) \n",
    "                    \n",
    "        if 'BW' in str(i['element']):\n",
    "            claim_id = make_claim(item, name_fiaf['ontology/property/colour'], name_fiaf['ontology/item/black_and_white'])   \n",
    "            reference(claim_id, name_bfi['ontology/item/bfi'])   \n",
    "            \n",
    "        if 'Colour' in str(i['element']):\n",
    "            claim_id = make_claim(item, name_fiaf['ontology/property/colour'], name_fiaf['ontology/item/colour'])   \n",
    "            reference(claim_id, name_bfi['ontology/item/bfi'])   \n",
    "\n",
    "        for k, v in {'VHS':name_fiaf['ontology/item/master'], 'DVD':name_fiaf['ontology/item/viewing'],\n",
    "                     'DB':name_fiaf['ontology/item/digibeta']}.items():\n",
    "            if i['video'] == k:                       \n",
    "                claim_id = make_claim(item, name_fiaf['ontology/property/specific_carrier'], v)   \n",
    "                reference(claim_id, name_bfi['ontology/item/bfi'])  \n",
    "\n",
    "        if i['dure']:\n",
    "            claim_id = make_claim(item, name_fiaf['ontology/property/extent_feet'], rdflib.Literal(i['dure']))\n",
    "            reference(claim_id, name_bfi['ontology/item/bfi'])               \n",
    "            \n",
    "        make_claim(work, name_fiaf['ontology/property/manifestation'], manifestation)\n",
    "        make_claim(manifestation, name_fiaf['ontology/property/item'], item)   \n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12438\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph.serialize(destination=str(pathlib.Path.cwd() / 'british_film_institute.ttl'), format=\"turtle\")\n",
    "print(len(graph))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
