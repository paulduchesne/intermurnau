{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# questions for NFA (or google translate)\n",
    "# 1. I understand NAZEV-ORIGIN (original title), but what is NAZEV-SKUT, NAZEV-PRAC, NAZEV-KATALOG\n",
    "# 2. no authority ids for individuals?\n",
    "\n",
    "# notes, write labels for agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letzte Mann,Der\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load and normalise data\n",
    "\n",
    "import pathlib, xmltodict, json\n",
    "import pydash, uuid, rdflib\n",
    "\n",
    "pathway = pathlib.Path.cwd() / 'murnau_ais_export.xml'\n",
    "\n",
    "data = list()\n",
    "with open(pathway) as source_data:\n",
    "    source_data = source_data.read().split('</FILM>')\n",
    "    for d in source_data:\n",
    "        try:\n",
    "            data.append(xmltodict.parse(d+'</FILM>'))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "with open(pathlib.Path.cwd() / 'nfa.json', 'w') as nfa_json:\n",
    "    json.dump(data, nfa_json)\n",
    "\n",
    "# last laugh filter\n",
    "murnau = ['2200560']\n",
    "data = [x for x in data if pydash.get(x, 'FILM.FILMID') in murnau]\n",
    "\n",
    "for x in data:\n",
    "    print(pydash.get(x, 'FILM.NAZEV-ORIGIN'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define graph and namespace\n",
    "\n",
    "graph = rdflib.Graph()\n",
    "\n",
    "name_nfa = rdflib.Namespace('https://www.nfa.cz/') \n",
    "name_wb = rdflib.Namespace('http://wikibas.se/ontology')\n",
    "name_fiaf = rdflib.Namespace(\"https://www.fiafnet.org/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# institute specific entities\n",
    "\n",
    "graph.add((name_nfa['ontology/property/nfa_work_id'], rdflib.RDFS.label, rdflib.Literal('National Film Archive work ID'))) \n",
    "graph.add((name_nfa['ontology/property/nfa_agent_id'], rdflib.RDFS.label, rdflib.Literal('National Film Archive agent ID'))) \n",
    "\n",
    "claim1 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "graph.add((name_nfa['ontology/item/nfa'], rdflib.RDFS.label, rdflib.Literal('National Film Archive', lang='en'))) \n",
    "graph.add((name_nfa['ontology/item/nfa'], rdflib.RDFS.label, rdflib.Literal('Národní filmový archiv', lang='cs'))) \n",
    "graph.add((name_nfa['ontology/item/nfa'], name_wb['#claim'], claim1))\n",
    "graph.add((claim1, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/holding_institution'])) \n",
    "\n",
    "claim2 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "graph.add((name_nfa['ontology/item/nazev_origin'], rdflib.RDFS.label, rdflib.Literal('nazev origin', lang='cs'))) \n",
    "graph.add((name_nfa['ontology/item/nazev_origin'], name_wb['#claim'], claim2)) \n",
    "graph.add((claim2, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/title_type'])) \n",
    "\n",
    "claim3 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "graph.add((name_nfa['ontology/item/obsazeni'], rdflib.RDFS.label, rdflib.Literal('obsazení', lang='cs'))) \n",
    "graph.add((name_nfa['ontology/item/obsazeni'], name_wb['#claim'], claim3)) \n",
    "graph.add((claim3, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/agent_type'])) \n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# reference\n",
    "\n",
    "def reference(claim_id):\n",
    "    \n",
    "    ref_id = name_nfa[f\"resource/reference/{uuid.uuid4()}\"]\n",
    "    graph.add((claim_id, name_wb['#reference'], ref_id))\n",
    "    graph.add((ref_id, name_fiaf['ontology/property/contributed_by'], name_nfa['ontology/item/nfa']))  \n",
    "\n",
    "print(len(graph))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write work specifics\n",
    "\n",
    "for x in data:\n",
    "    work_id = pydash.get(x, 'FILM.FILMID')\n",
    "    work = name_nfa[f\"resource/work/{work_id}\"]\n",
    "    \n",
    "    claim1 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "    claim2 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]    \n",
    "\n",
    "    graph.add((work, name_wb['#claim'], claim1))\n",
    "    graph.add((claim1, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/work']))\n",
    "\n",
    "    graph.add((work, name_wb['#claim'], claim2))\n",
    "    graph.add((claim2, name_nfa['ontology/property/nfa_work_id'], rdflib.Literal(work_id)))  \n",
    "    \n",
    "print(len(graph))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write original title\n",
    "\n",
    "for x in data:\n",
    "    work_id = pydash.get(x, 'FILM.FILMID')\n",
    "    work = name_nfa[f\"resource/work/{work_id}\"]  \n",
    "    \n",
    "    claim1 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "    qual1 = name_nfa[f\"resource/qualifier/{uuid.uuid4()}\"]    \n",
    "    ref1 = name_nfa[f\"resource/reference/{uuid.uuid4()}\"]  \n",
    "    \n",
    "    title = str(pydash.get(x, 'FILM.NAZEV-ORIGIN')).split(',')\n",
    "    if len(title) > 1:\n",
    "        title = title[1].strip()+' '+title[0].strip()\n",
    "    else:\n",
    "        title = title[0]    \n",
    "\n",
    "    graph.add((work, name_wb['#claim'], claim1))\n",
    "    graph.add((claim1, name_fiaf['ontology/property/title'], rdflib.Literal(title)))\n",
    "        \n",
    "    graph.add((claim1, name_wb['#qualifier'], qual1))\n",
    "    graph.add((qual1, name_fiaf['ontology/property/title_type'], name_nfa['ontology/item/nazev_origin']))\n",
    "            \n",
    "    graph.add((claim1, name_wb['#reference'], ref1))\n",
    "    graph.add((ref1, name_fiaf['ontology/property/contributed_by'], name_nfa['ontology/item/nfa']))  \n",
    "            \n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write cast agents\n",
    "\n",
    "for x in data:\n",
    "    work_id = pydash.get(x, 'FILM.FILMID')\n",
    "    work = name_nfa[f\"resource/work/{work_id}\"]  \n",
    "    for o in pydash.get(x, 'FILM.OBSAZENI'):\n",
    "\n",
    "        agent1 = name_nfa[f\"resource/agent/{uuid.uuid4()}\"]\n",
    "        role1 = name_nfa[f\"resource/role/{uuid.uuid4()}\"] \n",
    "        \n",
    "        claim1 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "        claim2 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "        claim3 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "        claim4 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "        claim5 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]        \n",
    "\n",
    "        qual1 = name_nfa[f\"resource/qualifier/{uuid.uuid4()}\"]  \n",
    "        qual2 = name_nfa[f\"resource/qualifier/{uuid.uuid4()}\"]          \n",
    "        \n",
    "        graph.add((work, name_wb['#claim'], claim1))\n",
    "        graph.add((claim1, name_fiaf['ontology/property/agent_cast'], agent1))\n",
    "        \n",
    "        graph.add((claim1, name_wb['#qualifier'], qual1))\n",
    "        graph.add((qual1, name_fiaf['ontology/property/agent_type'], name_nfa['ontology/item/obsazeni']))\n",
    "\n",
    "        graph.add((agent1, name_wb['#claim'], claim2))\n",
    "        graph.add((claim2, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/agent']))  \n",
    "\n",
    "        graph.add((agent1, name_wb['#claim'], claim3))\n",
    "        graph.add((claim3, name_fiaf['ontology/property/forename'], rdflib.Literal(pydash.get(o, 'HEREC.JMENO'))))  \n",
    "   \n",
    "        graph.add((agent1, name_wb['#claim'], claim4))\n",
    "        graph.add((claim4, name_fiaf['ontology/property/surname'], rdflib.Literal(pydash.get(o, 'HEREC.PRIJMENI')))) \n",
    "\n",
    "        reference(claim1)\n",
    "        reference(claim3)\n",
    "        reference(claim4)        \n",
    "            \n",
    "        if 'ROLE' in o:    \n",
    "            \n",
    "            graph.add((claim1, name_wb['#qualifier'], qual2))\n",
    "            graph.add((qual2, name_fiaf['ontology/property/role'], role1))        \n",
    "\n",
    "            graph.add((role1, name_wb['#claim'], claim5))\n",
    "            graph.add((claim5, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/role']))      \n",
    "            graph.add((role1, rdflib.RDFS.label, rdflib.Literal(pydash.get(o, 'ROLE'), lang='cs'))) # instane of title type (item)\n",
    "    \n",
    "        label_name = pydash.get(o, 'HEREC.JMENO')+' '+pydash.get(o, 'HEREC.PRIJMENI')\n",
    "        graph.add((agent1, rdflib.RDFS.label, rdflib.Literal(label_name, lang='cs')))     \n",
    "    \n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write credit agents\n",
    "\n",
    "def reference(claim_id):\n",
    "    \n",
    "    ref_id = name_nfa[f\"resource/reference/{uuid.uuid4()}\"]\n",
    "    graph.add((claim_id, name_wb['#reference'], ref_id))\n",
    "    graph.add((ref_id, name_fiaf['ontology/property/contributed_by'], name_nfa['ontology/item/nfa']))  \n",
    "    \n",
    "def write_credit(c, y):\n",
    "    \n",
    "    agent1 = name_nfa[f\"resource/agent/{uuid.uuid4()}\"]\n",
    "    role1 = name_nfa[f\"resource/role/{uuid.uuid4()}\"] \n",
    "\n",
    "    claim1 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "    claim2 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "    claim3 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "    claim4 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "    claim5 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]        \n",
    "\n",
    "    qual1 = name_nfa[f\"resource/qualifier/{uuid.uuid4()}\"]  \n",
    "    qual2 = name_nfa[f\"resource/qualifier/{uuid.uuid4()}\"]          \n",
    "\n",
    "    graph.add((work, name_wb['#claim'], claim1))\n",
    "    graph.add((claim1, name_fiaf['ontology/property/agent_credit'], agent1))\n",
    "\n",
    "    graph.add((claim1, name_wb['#qualifier'], qual1))\n",
    "    graph.add((qual1, name_fiaf['ontology/property/agent_type'], name_nfa[f'ontology/item/{y.lower()}']))\n",
    "\n",
    "    graph.add((agent1, name_wb['#claim'], claim2))\n",
    "    graph.add((claim2, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/agent']))  \n",
    "\n",
    "    graph.add((agent1, name_wb['#claim'], claim3))\n",
    "    graph.add((claim3, name_fiaf['ontology/property/forename'], rdflib.Literal(pydash.get(c, 'JMENO'))))  \n",
    "\n",
    "    graph.add((agent1, name_wb['#claim'], claim4))\n",
    "    graph.add((claim4, name_fiaf['ontology/property/surname'], rdflib.Literal(pydash.get(c, 'PRIJMENI')))) \n",
    "    \n",
    "    reference(claim1)\n",
    "    reference(claim3)\n",
    "    reference(claim4)  \n",
    "    \n",
    "#     print(pydash.get(o, 'JMENO'), pydash.get(o, 'PRIJMENI'))\n",
    "    label_name = pydash.get(c, 'JMENO')+' '+pydash.get(c, 'PRIJMENI')\n",
    "    graph.add((agent1, rdflib.RDFS.label, rdflib.Literal(label_name, lang='cs')))     \n",
    "        \n",
    "\n",
    "for x in data:\n",
    "    work_id = pydash.get(x, 'FILM.FILMID')\n",
    "    work = name_nfa[f\"resource/work/{work_id}\"]  \n",
    "    for y in ['REZIE', 'SCENAR', 'KAMERA', 'HUDBA']:\n",
    "\n",
    "        claim9 = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]\n",
    "        graph.add((name_nfa[f'ontology/item/{y.lower()}'], rdflib.RDFS.label, rdflib.Literal(y.lower(), lang='cs'))) \n",
    "        graph.add((name_nfa[f'ontology/item/{y.lower()}'], name_wb['#claim'], claim9)) \n",
    "        graph.add((claim9, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/agent_type'])) \n",
    "        \n",
    "        if 'JMENO' in pydash.get(x, f'FILM.{y}'):\n",
    "            c = pydash.get(x, f'FILM.{y}')     \n",
    "            write_credit(c, y)\n",
    "        else:\n",
    "            credits = pydash.get(x, f'FILM.{y}')   \n",
    "            for c in credits:\n",
    "                write_credit(c, y)\n",
    "                                                                                                \n",
    "print(len(graph))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# what next, you are getting away from events, lets do agents next.\n",
    "# I also do not feel happy with imposing work title, we should retain original title in native language\n",
    "# so define an original title as a title type with orig language, then you will merge these title types together\n",
    "# but you will not know this from the data, so at somepoint you will need to explicitly state\n",
    "# that original title (americans), orignaltitel (sw/de) and nevaz origin (cz) are all the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(graph.serialize(format=\"ttl\").decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph.serialize(destination=str(pathlib.Path.cwd() / 'nfa.ttl'), format=\"turtle\")\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
