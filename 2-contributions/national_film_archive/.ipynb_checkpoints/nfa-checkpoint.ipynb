{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# National Film Archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "\n",
    "import rdflib, pandas, pathlib, json\n",
    "import numpy, uuid, xmltodict, pydash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define graph and namespace\n",
    "\n",
    "graph = rdflib.Graph()\n",
    "name_nfa = rdflib.Namespace('https://www.nfa.cz/') \n",
    "name_wb = rdflib.Namespace('http://wikibas.se/ontology')\n",
    "name_fiaf = rdflib.Namespace('https://www.fiafnet.org/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# useful functions\n",
    "\n",
    "def make_claim(s, p, o):        \n",
    "    claim_id = name_nfa[f\"resource/claim/{uuid.uuid4()}\"]    \n",
    "    graph.add((s, name_wb['#claim'], claim_id))\n",
    "    graph.add((claim_id, p, o))\n",
    "    return claim_id\n",
    "\n",
    "def make_qual(s, p, o):\n",
    "    qual_id = name_nfa[f\"resource/qualifier/{uuid.uuid4()}\"]       \n",
    "    graph.add((s, name_wb['#qualifier'], qual_id))\n",
    "    graph.add((qual_id, p, o))\n",
    "    return qual_id\n",
    "\n",
    "def reference(claim_id, institute):\n",
    "    ref_id = name_nfa[f\"resource/reference/{uuid.uuid4()}\"]\n",
    "    graph.add((claim_id, name_wb['#reference'], ref_id))\n",
    "    graph.add((ref_id, name_fiaf['ontology/property/contributed_by'], institute)) \n",
    "\n",
    "def single_list(data):  \n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "    else:\n",
    "        return [data]   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define institution\n",
    "\n",
    "graph.add((name_nfa['ontology/item/nfa'], rdflib.RDFS.label, rdflib.Literal('National Film Archive', lang='en'))) \n",
    "graph.add((name_nfa['ontology/item/nfa'], rdflib.RDFS.label, rdflib.Literal('Národní filmový archiv', lang='cs'))) \n",
    "make_claim(name_nfa['ontology/item/nfa'], name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/holding_institution'])\n",
    "make_claim(name_nfa['ontology/item/nfa'], name_fiaf['ontology/property/located_in'], name_fiaf['ontology/item/czech_republic'])\n",
    "\n",
    "print(len(graph)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# format data\n",
    "\n",
    "pathway = pathlib.Path.cwd() / 'murnau_ais_export.xml'\n",
    "\n",
    "data = list()\n",
    "with open(pathway) as source_data:\n",
    "    source_data = source_data.read().split('</FILM>')\n",
    "    for d in source_data:\n",
    "        try:\n",
    "            data.append(xmltodict.parse(d+'</FILM>'))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "with open(pathlib.Path.cwd() / 'nfa.json', 'w') as nfa_json:\n",
    "    json.dump(data, nfa_json)\n",
    "    \n",
    "print(len(graph))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write work\n",
    "\n",
    "for x in data:\n",
    "    work_id = pydash.get(x, 'FILM.FILMID')\n",
    "    work = name_nfa[f\"resource/work/{work_id}\"]\n",
    "    \n",
    "    make_claim(work, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/work'])\n",
    "    claim1 = make_claim(work, name_fiaf['ontology/property/external_id'], rdflib.Literal(work_id))\n",
    "    make_qual(claim1, name_fiaf['ontology/property/institution'], name_nfa['ontology/item/nfa'])\n",
    "    reference(claim1, name_nfa['ontology/item/nfa'])     \n",
    "    \n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write original title\n",
    "\n",
    "for x in data:\n",
    "    work_id = pydash.get(x, 'FILM.FILMID')\n",
    "    work = name_nfa[f\"resource/work/{work_id}\"] \n",
    "\n",
    "    title = str(pydash.get(x, 'FILM.NAZEV-ORIGIN')).split(',')\n",
    "    if len(title) > 1:\n",
    "        title = title[1].strip()+' '+title[0].strip()\n",
    "    else:\n",
    "        title = title[0] \n",
    "\n",
    "    claim1 = make_claim(work, name_fiaf['ontology/property/title'], rdflib.Literal(title))\n",
    "    make_qual(claim1, name_fiaf['ontology/property/title_type'], name_fiaf['ontology/item/original_title'])\n",
    "    reference(claim1, name_nfa['ontology/item/nfa'])    \n",
    "        \n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4430\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write agent data\n",
    "\n",
    "def write_credit(work_data, dict_key, agent_type): \n",
    "\n",
    "    work_id = pydash.get(x, 'FILM.FILMID')\n",
    "    work = name_nfa[f\"resource/work/{work_id}\"] \n",
    "    if pydash.get(x, f'FILM.{dict_key}') != None:\n",
    "        agent_data = single_list(pydash.get(x, f'FILM.{dict_key}'))\n",
    "        for a in agent_data:\n",
    "            agent = name_nfa[f\"resource/agent/{uuid.uuid4()}\"]\n",
    "                 \n",
    "            claim1 = make_claim(work, name_fiaf['ontology/property/agent'], agent)\n",
    "            make_qual(claim1, name_fiaf['ontology/property/agent_type'], agent_type)                \n",
    "            reference(claim1, name_nfa['ontology/item/nfa']) \n",
    "                \n",
    "            make_claim(agent, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/agent']) \n",
    "            \n",
    "            if dict_key == 'OBSAZENI':\n",
    "                fore = pydash.get(a, 'HEREC.JMENO')\n",
    "                sur = pydash.get(a, 'HEREC.PRIJMENI')\n",
    "            else:\n",
    "                fore = pydash.get(a, 'JMENO')\n",
    "                sur = pydash.get(a, 'PRIJMENI')     \n",
    "            \n",
    "            if fore != None:\n",
    "                claim3 = make_claim(agent, name_fiaf['ontology/property/forename'], rdflib.Literal(fore))\n",
    "                reference(claim3, name_nfa['ontology/item/nfa'])  \n",
    "            if sur != None:\n",
    "                claim4 = make_claim(agent, name_fiaf['ontology/property/surname'], rdflib.Literal(sur))\n",
    "                reference(claim4, name_nfa['ontology/item/nfa'])             \n",
    "\n",
    "            claim9 = make_claim(agent, name_fiaf['ontology/property/work'], work)    \n",
    "            reference(claim9, name_nfa['ontology/item/nfa'])                  \n",
    "                        \n",
    "for x in data:\n",
    "    \n",
    "    write_credit(x, 'OBSAZENI', name_fiaf['ontology/item/cast'])\n",
    "    write_credit(x, 'REZIE', name_fiaf['ontology/item/director']) \n",
    "    write_credit(x, 'KAMERA', name_fiaf['ontology/item/cinematographer'])       \n",
    "    write_credit(x, 'SCENAR', name_fiaf['ontology/item/screenwriter'])  \n",
    "    write_credit(x, 'HUDBA', name_fiaf['ontology/item/composer'])      \n",
    "        \n",
    "print(len(graph))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5110\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write items and manifestations\n",
    "\n",
    "for x in data:\n",
    "    for m in single_list(pydash.get(x, 'FILM.MATERIAL')):\n",
    "        manifestation = name_nfa[f\"resource/manifestation/{uuid.uuid4()}\"]\n",
    "        make_claim(manifestation, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/manifestation'])\n",
    "        make_claim(manifestation, name_fiaf['ontology/property/manifestation_of'], work)\n",
    "        \n",
    "        item_id = pydash.get(m, 'KLIC.MATERIALID')\n",
    "        item = name_nfa[f\"resource/item/{item_id}\"]\n",
    "        \n",
    "        make_claim(item, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/item'])        \n",
    "        make_claim(item, name_fiaf['ontology/property/item_of'], manifestation)  \n",
    "\n",
    "        claim1 = make_claim(item, name_fiaf['ontology/property/held_at'], name_nfa['ontology/item/nfa'])\n",
    "        reference(claim1, name_nfa['ontology/item/nfa'])          \n",
    "        \n",
    "        claim2 = make_claim(item, name_fiaf['ontology/property/external_id'], rdflib.Literal(item_id))\n",
    "        make_qual(claim2, name_fiaf['ontology/property/institution'], name_nfa['ontology/item/nfa'])          \n",
    "        reference(claim2, name_nfa['ontology/item/nfa'])          \n",
    "\n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/carrier'], name_fiaf['ontology/item/film'])   \n",
    "        reference(claim_id, name_nfa['ontology/item/nfa'])          \n",
    "        \n",
    "        for k, v in {'1':name_fiaf['ontology/item/original_negative'], '2':name_fiaf['ontology/item/sound_negative'], \n",
    "                    '6':name_fiaf['ontology/item/sound_negative'], '8':name_fiaf['ontology/item/duplicate_negative'], \n",
    "                    '9':name_fiaf['ontology/item/print'], '10':name_fiaf['ontology/item/print']}.items():\n",
    "            if  m['MATERIAL'] == k:\n",
    "                claim_id = make_claim(item, name_fiaf['ontology/property/element'], v)   \n",
    "                reference(claim_id, name_nfa['ontology/item/nfa'])          \n",
    "        \n",
    "        if m['FORMAT-MATER'] == '02':\n",
    "            claim_id = make_claim(item, name_fiaf['ontology/property/specific_carrier'], name_fiaf['ontology/item/35mm'])   \n",
    "            reference(claim_id, name_nfa['ontology/item/nfa']) \n",
    "#             claim_id = make_claim(item, name_fiaf['ontology/property/aspect_ratio'], name_fiaf['ontology/item/133'])   \n",
    "#             reference(claim_id, name_nfa['ontology/item/nfa'])             \n",
    "        elif m['FORMAT-MATER'] == '03':\n",
    "            claim_id = make_claim(item, name_fiaf['ontology/property/specific_carrier'], name_fiaf['ontology/item/35mm'])   \n",
    "            reference(claim_id, name_nfa['ontology/item/nfa']) \n",
    "#             claim_id = make_claim(item, name_fiaf['ontology/property/aspect_ratio'], name_fiaf['ontology/item/137'])   \n",
    "#             reference(claim_id, name_nfa['ontology/item/nfa']) \n",
    "        elif m['FORMAT-MATER'] == '09':            \n",
    "            claim_id = make_claim(item, name_fiaf['ontology/property/specific_carrier'], name_fiaf['ontology/item/16mm'])   \n",
    "            reference(claim_id, name_nfa['ontology/item/nfa']) \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        for k, v in {'N':name_fiaf['ontology/item/nitrate'], 'A':name_fiaf['ontology/item/acetate'], 'P':name_fiaf['ontology/item/polyester']}.items():\n",
    "            if  m['DRUH-PODKLADU'] == k:\n",
    "                claim4 = make_claim(item, name_fiaf['ontology/property/base'], v)   \n",
    "                reference(claim4, name_nfa['ontology/item/nfa'])          \n",
    "        \n",
    "        make_claim(work, name_fiaf['ontology/property/manifestation'], manifestation)\n",
    "        make_claim(manifestation, name_fiaf['ontology/property/item'], item)          \n",
    "        \n",
    "print(len(graph)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5110\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph.serialize(destination=str(pathlib.Path.cwd() / 'nfa.ttl'), format=\"turtle\")\n",
    "print(len(graph))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
