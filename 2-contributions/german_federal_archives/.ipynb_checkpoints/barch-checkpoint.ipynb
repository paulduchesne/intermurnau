{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bundesarchiv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "\n",
    "import rdflib, pandas, pathlib, json\n",
    "import numpy, uuid, xmltodict, pydash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define graph and namespace\n",
    "\n",
    "graph = rdflib.Graph()\n",
    "name_ba = rdflib.Namespace('https://www.bundesarchiv.de/') \n",
    "name_wb = rdflib.Namespace('http://wikibas.se/ontology')\n",
    "name_fiaf = rdflib.Namespace('https://www.fiafnet.org/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# useful functions\n",
    "\n",
    "def make_claim(s, p, o):        \n",
    "    claim_id = name_ba[f\"resource/claim/{uuid.uuid4()}\"]    \n",
    "    graph.add((s, name_wb['#claim'], claim_id))\n",
    "    graph.add((claim_id, p, o))\n",
    "    return claim_id\n",
    "\n",
    "def make_qual(s, p, o):\n",
    "    qual_id = name_ba[f\"resource/qualifier/{uuid.uuid4()}\"]       \n",
    "    graph.add((s, name_wb['#qualifier'], qual_id))\n",
    "    graph.add((qual_id, p, o))\n",
    "    return qual_id\n",
    "\n",
    "def reference(claim_id, institute):\n",
    "    ref_id = name_ba[f\"resource/reference/{uuid.uuid4()}\"]\n",
    "    graph.add((claim_id, name_wb['#reference'], ref_id))\n",
    "    graph.add((ref_id, name_fiaf['ontology/property/contributed_by'], institute))  \n",
    "    \n",
    "def single_list(data):  \n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "    else:\n",
    "        return [data]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define institution\n",
    "\n",
    "graph.add((name_ba['ontology/item/barch'], rdflib.RDFS.label, rdflib.Literal('German Federal Archives', lang='en'))) \n",
    "graph.add((name_ba['ontology/item/barch'], rdflib.RDFS.label, rdflib.Literal('Bundesarchiv', lang='de'))) \n",
    "make_claim(name_ba['ontology/item/barch'], name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/holding_institution'])\n",
    "make_claim(name_ba['ontology/item/barch'], name_fiaf['ontology/property/located_in'], name_fiaf['ontology/item/germany'])\n",
    "\n",
    "print(len(graph)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# format data\n",
    "\n",
    "data = pandas.read_csv(pathlib.Path.cwd() / 'Murnau_BArch_210106.csv', dtype='str')\n",
    "data = data.loc[data.MURNAU_ROLE.isin(['Regie / Spielleitung / Realisation'])]\n",
    "data = data.replace({'WORK_ID':{'307190':'1210', '307191':'5431'}})\n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write work\n",
    "\n",
    "for x in (data.WORK_ID.unique()):\n",
    "    work_id = x\n",
    "    work = name_ba[f\"resource/work/{work_id}\"]\n",
    "    \n",
    "    make_claim(work, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/work'])\n",
    "    claim1 = make_claim(work, name_fiaf['ontology/property/external_id'], rdflib.Literal(work_id))\n",
    "    make_qual(claim1, name_fiaf['ontology/property/institution'], name_ba['ontology/item/barch'])\n",
    "    reference(claim1, name_ba['ontology/item/barch'])     \n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write title\n",
    "\n",
    "title_data = data[['WORK_ID', 'TITLE_ID', 'TITLE', 'TITLE_TYPE']].drop_duplicates()\n",
    "title_data = title_data.loc[title_data.TITLE_TYPE.isin(['Originaltitel'])]\n",
    "title_data = title_data.sort_values(by='TITLE_ID', ascending=False)\n",
    "title_data = title_data.drop_duplicates(subset=['WORK_ID'], keep='first')\n",
    "\n",
    "for x in title_data.to_dict(orient='records'):\n",
    "    \n",
    "    work_id = x['WORK_ID']\n",
    "    work = name_ba[f\"resource/work/{work_id}\"]\n",
    "\n",
    "    claim1 = make_claim(work, name_fiaf['ontology/property/title'], rdflib.Literal(x['TITLE']))\n",
    "    make_qual(claim1, name_fiaf['ontology/property/title_type'], name_fiaf['ontology/item/original_title'])\n",
    "    reference(claim1, name_ba['ontology/item/barch'])     \n",
    "\n",
    "print(len(graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3622\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write agents \n",
    "\n",
    "agent_data = data[['WORK_ID', 'CC_FUNCTION', 'CC_PERSON_ID', 'CREDIT_CAST_NAME']].drop_duplicates()\n",
    "\n",
    "def write_credit(role, uri):\n",
    "    for x in agent_data.to_dict(orient='records'):\n",
    "        if x['CC_FUNCTION'] == role and x['CREDIT_CAST_NAME'] is not numpy.nan and 'Ufa' not in x['CREDIT_CAST_NAME']:\n",
    "\n",
    "            name = x['CREDIT_CAST_NAME'].replace('°','').replace('(ZDF-Fassg. 1983)','')\n",
    "            if '.' in name:\n",
    "                name = name.split('.')[-1]\n",
    "            if ',' in name:\n",
    "                name = name.split(',')[1].strip()+' '+name.split(',')[0].strip()\n",
    "            name = name.strip()\n",
    "     \n",
    "            if len(name) > 4:\n",
    "                name = [y for y in name.split(' ') if y != '']                \n",
    "\n",
    "                work_id = x['WORK_ID']\n",
    "                work = name_ba[f\"resource/work/{work_id}\"]\n",
    "\n",
    "                agent_id = x['CC_PERSON_ID']\n",
    "                agent = name_ba[f\"resource/agent/{agent_id}\"]  \n",
    "\n",
    "                claim_id = make_claim(work, name_fiaf['ontology/property/agent'], agent)\n",
    "                make_qual(claim_id, name_fiaf['ontology/property/agent_type'], uri)                \n",
    "                reference(claim_id, name_ba['ontology/item/barch'])    \n",
    "\n",
    "                make_claim(agent, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/agent']) \n",
    "\n",
    "                claim_id = make_claim(agent, name_fiaf['ontology/property/external_id'], rdflib.Literal(agent_id))\n",
    "                make_qual(claim_id, name_fiaf['ontology/property/institution'], name_ba['ontology/item/barch'])\n",
    "                reference(claim_id, name_ba['ontology/item/barch']) \n",
    "\n",
    "                if len(name) > 1:\n",
    "                    claim_id = make_claim(agent, name_fiaf['ontology/property/forename'], rdflib.Literal(' '.join(name[:-1])))\n",
    "                    reference(claim_id, name_ba['ontology/item/barch'])                      \n",
    "                \n",
    "                claim_id = make_claim(agent, name_fiaf['ontology/property/surname'], rdflib.Literal(name[-1]))\n",
    "                reference(claim_id, name_ba['ontology/item/barch'])                     \n",
    "\n",
    "                claim_id = make_claim(agent, name_fiaf['ontology/property/work'], work)    \n",
    "                reference(claim_id, name_ba['ontology/item/barch']) \n",
    "\n",
    "write_credit('Darsteller', name_fiaf['ontology/item/cast'])\n",
    "write_credit('Regie / Spielleitung / Realisation', name_fiaf['ontology/item/director']) \n",
    "write_credit('Produzent', name_fiaf['ontology/item/producer'])   \n",
    "write_credit('Kamera/Bild/Bildgestaltung/Fotografie', name_fiaf['ontology/item/cinematographer']) \n",
    "write_credit('Redaktion', name_fiaf['ontology/item/editor'])     \n",
    "write_credit('Drehbuch', name_fiaf['ontology/item/screenwriter'])  \n",
    "write_credit('Musik (Filmkomponist)', name_fiaf['ontology/item/composer'])\n",
    "\n",
    "print(len(graph))             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3890\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write events\n",
    "\n",
    "event_col = ['WORK_ID', 'EVENT_TYPE', 'EVENT_AGENT_FUNCTION', 'DATE_FROM', 'DECISION']\n",
    "\n",
    "decision_event = data.loc[data.EVENT_AGENT_FUNCTION.isin(['Prüfstelle'])][event_col].drop_duplicates().dropna(subset=['DATE_FROM'])\n",
    "for x in decision_event.to_dict(orient='records'):\n",
    "    work_id = x['WORK_ID']\n",
    "    work = name_ba[f\"resource/work/{work_id}\"]\n",
    "    \n",
    "    date = pandas.to_datetime(x['DATE_FROM']).strftime('%Y-%m-%d')\n",
    "    claim_id = make_claim(work, name_fiaf['ontology/property/event'], rdflib.Literal(date))\n",
    "    make_qual(claim_id, name_fiaf['ontology/property/event_type'], name_fiaf['ontology/item/decision_censorship']) \n",
    "    make_qual(claim_id, name_fiaf['ontology/property/country'], name_fiaf['ontology/item/germany'])  \n",
    "    make_qual(claim_id, name_fiaf['ontology/property/certificate'], rdflib.Literal(x['DECISION']))  \n",
    "    reference(claim_id, name_ba['ontology/item/barch']) \n",
    "\n",
    "publication_event = data.loc[data.EVENT_TYPE.isin(['PUBLIKATION'])][event_col].drop_duplicates().dropna(subset=['DATE_FROM'])\n",
    "for x in publication_event.to_dict(orient='records'):\n",
    "    work_id = x['WORK_ID']\n",
    "    work = name_ba[f\"resource/work/{work_id}\"]    \n",
    "    \n",
    "    date = pandas.to_datetime(x['DATE_FROM']).strftime('%Y-%m-%d')\n",
    "    claim_id = make_claim(work, name_fiaf['ontology/property/event'], rdflib.Literal(date))\n",
    "    make_qual(claim_id, name_fiaf['ontology/property/event_type'], name_fiaf['ontology/item/publication']) \n",
    "    make_qual(claim_id, name_fiaf['ontology/property/country'], name_fiaf['ontology/item/germany'])              \n",
    "    reference(claim_id, name_ba['ontology/item/barch']) \n",
    "\n",
    "print(len(graph))             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write manifestations / items\n",
    "\n",
    "item_data = data[['WORK_ID', 'SIGNATUR', 'CARRIER', 'MEDIENART', 'COLOUR', 'MEDIA_TYPE', 'MATERIAL_TYPE', \n",
    "                  'FILM_FORMAT', 'DURATION_MIN', 'LENGTH_M']].drop_duplicates()\n",
    "\n",
    "item_data = item_data.replace({'CARRIER':{'Triazetatzellulose': name_fiaf['ontology/item/acetate'], 'Zellulosenitrat': name_fiaf['ontology/item/nitrate'], \n",
    "                                          'Polyethylenterephtalat (Polyester) ':name_fiaf['ontology/item/polyester']}})\n",
    "item_data = item_data.replace({'MEDIENART':{'FILM': name_fiaf['ontology/item/film'], 'VIDEO': name_fiaf['ontology/item/video_tape'], \n",
    "                                            'DATEN':name_fiaf['ontology/item/digital']}})\n",
    "item_data = item_data.replace({'COLOUR':{'schwarz-weiß': name_fiaf['ontology/item/black_and_white'], 'Farbe': name_fiaf['ontology/item/colour'], \n",
    "                                         'schwarz-weiß und Farbe':name_fiaf['ontology/item/black_and_white_and_colour']}})\n",
    "item_data = item_data.replace({'MEDIA_TYPE':{'Bild': name_fiaf['ontology/item/silent'], 'Bild/Ton': name_fiaf['ontology/item/sound']}})\n",
    "item_data = item_data.replace({'MATERIAL_TYPE':{'Stumme Kopie ': name_fiaf['ontology/item/print'], 'VHS': name_fiaf['ontology/item/vhs'], \n",
    "                                             'Tonnegativ': name_fiaf['ontology/item/negative'], \n",
    "                                             'Bildduplikatnegativ': name_fiaf['ontology/item/duplicate_negative'], \n",
    "                                             'Stummes Duplikatnegativ': name_fiaf['ontology/item/duplicate_negative'], \n",
    "                                             'Kombinierte Kopie': name_fiaf['ontology/item/print'], 'VHS/BA': name_fiaf['ontology/item/vhs'], \n",
    "                                             'Umatic': name_fiaf['ontology/item/umatic'], \n",
    "                                             'Stummes Duplikatpositiv': name_fiaf['ontology/item/duplicate_positive'], \n",
    "                                             'Stummes Originalnegativ': name_fiaf['ontology/item/original_negative'], \n",
    "                                             'DVD/TC': name_fiaf['ontology/item/dvd'], 'DVD': name_fiaf['ontology/item/dvd'], \n",
    "                                             'Bildnegativ': name_fiaf['ontology/item/negative'], \n",
    "                                             'Intermediate Positive': name_fiaf['ontology/item/duplicate_positive'], \n",
    "                                             'Stummes Internegativ': name_fiaf['ontology/item/duplicate_negative'], \n",
    "                                             'VHS/BA + TC': name_fiaf['ontology/item/vhs'], 'VHS/TC': name_fiaf['ontology/item/vhs'], \n",
    "                                             'Bildpositiv': name_fiaf['ontology/item/duplicate_positive'], \n",
    "                                             'kombiniertes Duplikatnegativ': name_fiaf['ontology/item/duplicate_negative']}})\n",
    "item_data = item_data.replace({'FILM_FORMAT':{'35 mm': name_fiaf['ontology/item/35mm'], '16 mm': name_fiaf['ontology/item/16mm'], \n",
    "                                              '9,5 mm': name_fiaf['ontology/item/9mm']}})\n",
    "\n",
    "for x in item_data.to_dict(orient='records'):\n",
    "    \n",
    "    work_id = x['WORK_ID']\n",
    "    work = name_ba[f\"resource/work/{work_id}\"]\n",
    "    \n",
    "    manifestation = name_ba[f\"resource/manifestation/{uuid.uuid4()}\"]\n",
    "    \n",
    "    make_claim(manifestation, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/manifestation'])\n",
    "    make_claim(manifestation, name_fiaf['ontology/property/manifestation_of'], work)\n",
    "\n",
    "    item_id = x['SIGNATUR']\n",
    "    item = name_ba[f\"resource/item/{item_id}\"]     \n",
    "\n",
    "    make_claim(item, name_fiaf['ontology/property/instance_of'], name_fiaf['ontology/item/item'])        \n",
    "    make_claim(item, name_fiaf['ontology/property/item_of'], manifestation)  \n",
    "\n",
    "    claim_id = make_claim(item, name_fiaf['ontology/property/held_at'], name_ba['ontology/item/barch'])\n",
    "    reference(claim_id, name_ba['ontology/item/barch'])          \n",
    "        \n",
    "    claim_id = make_claim(item, name_fiaf['ontology/property/external_id'], rdflib.Literal(item_id))\n",
    "    make_qual(claim_id, name_fiaf['ontology/property/institution'], name_ba['ontology/item/barch'])\n",
    "    reference(claim_id, name_ba['ontology/item/barch'])    \n",
    "\n",
    "    if isinstance(x['CARRIER'], rdflib.URIRef): \n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/base'], x['CARRIER'])   \n",
    "        reference(claim_id, name_ba['ontology/item/barch'])      \n",
    "        \n",
    "    if isinstance(x['MEDIENART'], rdflib.URIRef): \n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/carrier'], x['MEDIENART'])   \n",
    "        reference(claim_id, name_ba['ontology/item/barch'])  \n",
    "        \n",
    "    if isinstance(x['FILM_FORMAT'], rdflib.URIRef): \n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/specific_carrier'], x['FILM_FORMAT'])   \n",
    "        reference(claim_id, name_ba['ontology/item/barch'])  \n",
    "        \n",
    "    if isinstance(x['MATERIAL_TYPE'], rdflib.URIRef): \n",
    "        if x['MATERIAL_TYPE'] in [name_fiaf['ontology/item/vhs'], name_fiaf['ontology/item/umatic'], name_fiaf['ontology/item/dvd']]:\n",
    "            claim_id = make_claim(item, name_fiaf['ontology/property/specific_carrier'], x['MATERIAL_TYPE'])   \n",
    "            reference(claim_id, name_ba['ontology/item/barch'])  \n",
    "        else:\n",
    "            claim_id = make_claim(item, name_fiaf['ontology/property/element'], x['MATERIAL_TYPE'])   \n",
    "            reference(claim_id, name_ba['ontology/item/barch'])             \n",
    "        \n",
    "    if isinstance(x['COLOUR'], rdflib.URIRef): \n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/colour'], x['COLOUR'])   \n",
    "        reference(claim_id, name_ba['ontology/item/barch'])         \n",
    "        \n",
    "    if isinstance(x['MEDIA_TYPE'], rdflib.URIRef): \n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/sound'], x['MEDIA_TYPE'])   \n",
    "        reference(claim_id, name_ba['ontology/item/barch'])         \n",
    "        \n",
    "    if x['LENGTH_M'] is not numpy.nan and str(x['LENGTH_M']) != '0':\n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/extent_metres'], rdflib.Literal(x['LENGTH_M']))   \n",
    "        reference(claim_id, name_ba['ontology/item/barch']) \n",
    "        \n",
    "    if x['DURATION_MIN'] is not numpy.nan and str(x['DURATION_MIN']) != '0':\n",
    "        claim_id = make_claim(item, name_fiaf['ontology/property/duration'], rdflib.Literal(x['DURATION_MIN']))   \n",
    "        reference(claim_id, name_ba['ontology/item/barch'])          \n",
    "    \n",
    "    make_claim(work, name_fiaf['ontology/property/manifestation'], manifestation)\n",
    "    make_claim(manifestation, name_fiaf['ontology/property/item'], item)   \n",
    "    \n",
    "print(len(graph))  # 12018   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph.serialize(destination=str(pathlib.Path.cwd() / 'barch.ttl'), format=\"turtle\")\n",
    "print(len(graph))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
